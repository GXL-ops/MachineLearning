{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 卷积神经网络(CNN)\n",
    "通过卷积神经网络对MNIST数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\nW1113 15:17:33.920734 10700 deprecation.py:323] From <ipython-input-3-e1dd9a9b7511>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1113 15:17:33.929707 10700 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\n",
      "W1113 15:17:33.945666 10700 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n",
      "W1113 15:17:34.757500 10700 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n",
      "W1113 15:17:34.791410 10700 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\n",
      "W1113 15:17:34.956970 10700 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\nExtracting MNIST_data\\t10k-images-idx3-ubyte.gz\nExtracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "number of train data is 55000\nnumber of test data is 10000\nMNIST ready\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "print(\"number of train data is %d\"%(mnist.train.num_examples))\n",
    "print(\"number of test data is %d\"%(mnist.test.num_examples))\n",
    "trainimg=mnist.train.images\n",
    "trainlabel=mnist.train.labels\n",
    "testimg=mnist.test.images\n",
    "testlabel=mnist.test.labels\n",
    "print(\"MNIST ready\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 构建卷积神经网络模型\n",
    "\n",
    "卷积神经网络模型的构建主要分为四步，构建输入层、隐层、输出层以及定义损失函数。\n",
    "\n",
    "对于隐层，我们构建了卷积层1-池化层1-卷积层2-池化层2-全连接神经网络层-Dropout层。\n",
    "\n",
    "1. 输出层：我们需要明确输入数据的维度即可，对于MNIST数据集来说，输入的是一张维度为28*28=784的灰度图，灰度图的通道是1\n",
    "\n",
    "2. 卷积层1：和全神经网络中输出值的处理类似，都需要依据权重和偏置项进行激活函数处理，可以表示为：\n",
    "$ y=f(conv(权重\\times x)+偏置项) $。\n",
    "首先运行卷积函数，然后计算偏置项，最后进行激活函数的处理。\n",
    "其中input为输入层的输入数据，维度为$[batch,in_height,in_width,in_channels]$，\n",
    "需要获取输入图像的数量、高度、宽度以及通道数。对于数量不考虑，标识-1；图片是28像素*28像素的灰度图，灰度图通道为1；如果是RGB彩图，通道为3，输入数据为\n",
    "$[-1,28,28,1]$\n",
    "\n",
    "3. 全连接神经网络在经过池化层2处理后的所有神经元节点作为全神经网络的输入神经元，所以关键就是获得池化层2处理后的神经元节点的个数。\n",
    "在池化层2处理后，总神经元节点数的计算公式为：单个特征映射$\\times$特征映射个数。其中特征映射个数为64，单个特征映射由原始图像的28$\\times$28，经过一次池化后为14$\\times$14，\n",
    "经过第二次池化后为7$\\times$7，总神经元节点数为7$\\times$7$\\times$64个。\n",
    "\n",
    "4. Dropot层，为了防止过拟合使用的，目的是让神经网络中的神经元随机出现“休眠”，让这些“休眠”的神经元不参与本次模型的运算。降低过拟合。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "W1113 15:17:41.433973 10700 deprecation.py:506] From <ipython-input-4-9e4f393dba0d>:70: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1113 15:17:41.554649 10700 deprecation.py:323] From <ipython-input-4-9e4f393dba0d>:90: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee `tf.nn.softmax_cross_entropy_with_logits_v2`.\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "CNN READY\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_input=784\n",
    "n_output=10\n",
    "# x=tf.placeholder(tf.float32,[None,n_input])\n",
    "# 卷积层输入数据\n",
    "# x_image=tf.reshape(x,[-1,28,28,1])\n",
    "# 卷积层定义\n",
    "# W_conv1=[3,3,1,32]\n",
    "# 平移步长\n",
    "# strides=[1,1,1,1]\n",
    "# tf.nn.conv2d(x,W_conv1,strides,padding='SAME')\n",
    "# 权重值初始化函数\n",
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "# 偏置项初始化函数\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "# 卷积计算函数\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "# 池化窗口定义\n",
    "ksize=[1,2,2,1]\n",
    "# 步长定义，在batch和channels上不进行池化，维度设置为1\n",
    "strides=[1,2,2,1]\n",
    "# 池化层函数定义(池化层使用卷积层的输出值)\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize,strides,padding='SAME')\n",
    "# 定义卷积神经网络函数\n",
    "def CNN_mnist(x):\n",
    "    # 定义图像数据\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image=tf.reshape(x,[-1,28,28,1])\n",
    "        \n",
    "    # 定义卷积层1和池化层1\n",
    "    # 实现卷积层1\n",
    "    with tf.name_scope('conv1'):\n",
    "        # 使用卷积核作为权重shape\n",
    "        W_conv1=weight_variable([3,3,1,32])\n",
    "        b_conv1=bias_variable([32])\n",
    "        # 对卷积核函数进行激活处理\n",
    "        h_conv1=tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)\n",
    "    # 池化层1中的具体实现(池化层使用卷积层的输出值)\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1=max_pool_2x2(h_conv1)\n",
    "        \n",
    "    \n",
    "    # 定义卷积层2和池化层2\n",
    "    # 实现卷积层2(输入使用上一层池化层的输出值)，32表示上一层核函数个数即32个特征映射，\n",
    "    # 即图像通道个数为32.而卷积核的个数必须在上一层的基础上有所增加，使用64\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2=weight_variable([3,3,32,64])\n",
    "        b_conv2=bias_variable([64])\n",
    "        #  对卷积核函数进行激活处理\n",
    "        h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "    # 池化层2中的具体实现\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2=max_pool_2x2(h_conv2)\n",
    "        \n",
    "    \n",
    "    # 构建全连接神经网络层的实现\n",
    "    # 定义fc1，将两次池化后的神经元转换为1D向量\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1=weight_variable([7*7*64,1024])\n",
    "        b_fc1=bias_variable([1024])\n",
    "        h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])\n",
    "        h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "        \n",
    "    \n",
    "    # Dropout层\n",
    "    # 让神经元随机休眠，防止过拟合\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob=tf.placeholder(tf.float32)\n",
    "        h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 输出层\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2=weight_variable([1024,10])\n",
    "        b_fc2=bias_variable([10])\n",
    "        # 输出不使用激活函数\n",
    "        y_conv=tf.matmul(h_fc1_drop,W_fc2)+b_fc2\n",
    "        print(\"CNN READY\")\n",
    "    return y_conv,keep_prob\n",
    "\n",
    "\n",
    "# 损失函数，使用最长用的softmax交叉熵损失函数\n",
    "x=tf.placeholder(tf.float32,[None,n_input])\n",
    "y_=tf.placeholder(tf.float32,[None,n_output])\n",
    "# 进行卷积神经网络训练\n",
    "y_conv,keep_prob=CNN_mnist(x)\n",
    "# 定义损失\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy=tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_conv)\n",
    "    cross_entropy=tf.reduce_mean(cross_entropy)\n",
    "# 优化器\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    # 函数是Adam优化算法：是一个寻找全局最优点的优化算法，引入了二次方梯度校正。\n",
    "    # 自适应优化器，包括tf.train.AdagradOptimizer和tf.train.AdamOptimizer，这些可以作为随时可用的替代品\n",
    "    train_step=tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "    # 旨在对所有步骤中的所有变量使用恒定的学习率。 \n",
    "    # train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行数据训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "step 0,training accuracy 0.13\n",
      "test accuracy 0.1009\n",
      "step 100,training accuracy 0.89\n",
      "test accuracy 0.8939\n",
      "step 200,training accuracy 0.92\n",
      "test accuracy 0.9215\n",
      "step 300,training accuracy 0.94\n",
      "test accuracy 0.9363\n",
      "step 400,training accuracy 0.95\n",
      "test accuracy 0.9435\n",
      "step 500,training accuracy 0.94\n",
      "test accuracy 0.9507\n",
      "step 600,training accuracy 0.99\n",
      "test accuracy 0.9516\n",
      "step 700,training accuracy 0.98\n",
      "test accuracy 0.9484\n",
      "step 800,training accuracy 0.92\n",
      "test accuracy 0.9461\n",
      "step 900,training accuracy 0.97\n",
      "test accuracy 0.9529\n",
      "step 1000,training accuracy 0.93\n",
      "test accuracy 0.9518\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 定义评测准确率的操作\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction=tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "    correct_prediction=tf.cast(correct_prediction,tf.float32)\n",
    "    accuracy=tf.reduce_mean(correct_prediction)\n",
    "# 初始化所有参数\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # 所有样本迭代1000次\n",
    "    training_epochs=1001\n",
    "    # 每次选择100个样本\n",
    "    batch_size=100\n",
    "    display_step=100\n",
    "    for i in range(training_epochs):\n",
    "        avg_cost=0\n",
    "        total_batch=int(mnist.train.num_examples/batch_size)\n",
    "        batch=mnist.train.next_batch(batch_size)\n",
    "        # 每个元素被保留下来的概率为0.7\n",
    "        sess.run(train_step,feed_dict={x:batch[0],y_:batch[1],keep_prob:0.7})\n",
    "        \n",
    "        # 评估模型,每100次评估一次\n",
    "        if i%display_step==0:\n",
    "            # t.eval()等效于sess.run(t).\n",
    "            train_accuracy=sess.run(accuracy,feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0})\n",
    "            print('step %d,training accuracy %g'%(i,train_accuracy))\n",
    "            test_accuracy=accuracy.eval(feed_dict={x:mnist.test.images,\n",
    "                                                   y_:mnist.test.labels,\n",
    "                                                   keep_prob:1.0})\n",
    "            print('test accuracy %g'%(test_accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}