{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 无监督学习\n",
    "## K均值聚类算法(K-Means)\n",
    "通过K-Means算法对MNIST数据集中的图片进行类型标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\nW1121 22:27:52.170346  7332 deprecation.py:323] From <ipython-input-2-4fd3111d64ec>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1121 22:27:52.172308  7332 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\n",
      "W1121 22:27:52.173302  7332 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n",
      "W1121 22:27:52.630082  7332 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n",
      "W1121 22:27:52.636072  7332 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\n",
      "W1121 22:27:52.721837  7332 deprecation.py:323] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\nExtracting MNIST_data\\t10k-images-idx3-ubyte.gz\nExtracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "number of train data is 55000\nnumber of test data is 10000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 加载数据\n",
    "from collections import Counter\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "print(\"number of train data is %d\"%(mnist.train.num_examples))\n",
    "print(\"number of test data is %d\"%(mnist.test.num_examples))\n",
    "# 使用训练集的图片数据作为输入数据\n",
    "# shape(55000,784)\n",
    "X=mnist.train.images\n",
    "# 样本数目\n",
    "N=mnist.train.num_examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 实现K均值聚类算法\n",
    "\n",
    "对于MNIST数据集来说，最终被分为0~9一共10类，因此K值取10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "W1121 22:27:53.666315  7332 deprecation.py:323] From <ipython-input-3-b8e6a17e4a75>:6: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "k=10\n",
    "# 最大迭代次数\n",
    "MAX_ITERS=100\n",
    "# 对于初始质心的选取，是在样本数据的边界通过随机选取的方式来实现的\n",
    "start_pos=tf.Variable(X[np.random.randint(X.shape[0],size=k),:],dtype=tf.float32)\n",
    "centroids=tf.Variable(start_pos.initialized_value(),'S',dtype=tf.float32)\n",
    "# 输入值\n",
    "points=tf.Variable(X,'X',dtype=tf.float32)\n",
    "ones_like=tf.ones((points.get_shape()[0],1))\n",
    "prev_assignments=tf.Variable(tf.zeros((points.get_shape()[0],),dtype=tf.int64))\n",
    "# 获取距离\n",
    "p1=tf.matmul(\n",
    "    tf.expand_dims(tf.reduce_sum(tf.square(points),1),1),\n",
    "    tf.ones(shape=(1,k))\n",
    ")\n",
    "p2=tf.transpose(tf.matmul(\n",
    "    tf.reshape(tf.reduce_sum(tf.square(centroids),1),shape=[-1,1]),\n",
    "    ones_like,\n",
    "    transpose_b=True\n",
    "))\n",
    "# 计算距离\n",
    "distance=tf.sqrt(tf.add(p1,p2)-2*tf.matmul(points,centroids,transpose_b=True))\n",
    "# 划分该点的簇\n",
    "point_to_centroid_assignment=tf.argmin(distance,axis=1)\n",
    "# 计算均值\n",
    "total=tf.unsorted_segment_sum(points,point_to_centroid_assignment,k)\n",
    "count=tf.unsorted_segment_sum(ones_like,point_to_centroid_assignment,k)\n",
    "means=total/count\n",
    "# 中心店是否变化\n",
    "is_continue=tf.reduce_any(tf.not_equal(point_to_centroid_assignment,prev_assignments))\n",
    "# 循环迭代\n",
    "with tf.control_dependencies([is_continue]):\n",
    "    loop=tf.group(centroids.assign(means),prev_assignments.assign(point_to_centroid_assignment))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 进行数据训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n9\n",
      "10\n",
      "11\n12\n",
      "13\n",
      "14\n15\n",
      "16\n",
      "17\n18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n28\n",
      "29\n30\n",
      "31\n32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n44",
      "\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n49",
      "\n",
      "50\n",
      "51\n52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n59\n",
      "60\n",
      "61\n",
      "62\n63",
      "\n",
      "64\n",
      "65\n",
      "66\n67",
      "\n",
      "68\n69\n",
      "70\n",
      "71\n",
      "72\n73\n",
      "74\n75\n",
      "76\n",
      "77\n78\n",
      "79\n80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n86\n",
      "87\n",
      "88\n",
      "89\n90\n",
      "91\n92\n",
      "93\nTrain finished.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    changed=True\n",
    "    iterNum=0\n",
    "    while changed and iterNum < MAX_ITERS:\n",
    "        iterNum+=1\n",
    "        # 数据训练\n",
    "        [changed,_]=sess.run([is_continue,loop])\n",
    "        res=sess.run(point_to_centroid_assignment)\n",
    "        print(iterNum)\n",
    "    print(\"Train finished.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型评估\n",
    "对每一个簇中的样本正确的标签进行统计，显示数量排在前三的标签及对应数量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[(0, 3935), (5, 50), (2, 43)]\n[(1, 2739), (2, 307), (8, 284)]\n[(7, 3453), (9, 2224), (4, 1703)]\n[(6, 3351), (4, 138), (0, 130)]\n[(8, 3250), (5, 977), (3, 856)]\n[(6, 1694), (5, 1312), (0, 1046)]\n[(4, 2865), (9, 2694), (7, 1644)]\n[(3, 3578), (5, 1670), (8, 937)]\n[(2, 3826), (3, 162), (6, 43)]\n[(1, 3395), (3, 365), (2, 332)]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 记录训练集的真实标签数据，为测试号准备率\n",
    "y_=mnist.train.labels\n",
    "y=[]\n",
    "for m in range(N):\n",
    "    for n in range(10):\n",
    "        if y_[m][n]==1:\n",
    "            y.append(n)\n",
    "\n",
    "# 评估。获取每个簇所有的点，按照真实标签的前三数量显示\n",
    "nums_in_clusters=[[] for i in range(10)]\n",
    "for i in range(N):\n",
    "    nums_in_clusters[res[i]].append(y[i])\n",
    "for i in range(10):\n",
    "    print(Counter(nums_in_clusters[i]).most_common(3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}